# AI in Healthcare Portfolio  
**Hillary Bruton**  
AI Strategy | Clinical Decision Support | Healthcare Risk Modeling | Governance & Trust  

---

## Executive Overview

This repository reflects a systems-level examination of artificial intelligence in healthcare, with a focus on clinical reliability, model governance, and responsible deployment.

My work centers on a core strategic insight:

> AI in healthcare is only as effective as the quality, structure, calibration, and governance of the clinical data and terminology on which it relies.

Rather than treating AI as a standalone innovation, this portfolio approaches healthcare AI as an integrated ecosystem challenge—spanning medical language, data integrity, model validation, workflow design, bias mitigation, and regulatory oversight.

---

## Strategic Lens

Across clinical decision support systems (CDSS), diagnostic AI, and risk modeling, the following themes consistently emerge:

- **Discrimination alone is insufficient** — calibration, subgroup equity, and external validity determine real-world safety.
- **Deployment is not the finish line** — monitoring, drift detection, and recalibration are continuous obligations.
- **Bias mitigation is institutional as well as technical** — governance frameworks must define acceptable risk thresholds.
- **AI must remain advisory** — clinician oversight and interpretability are foundational to trust.

---

## Applied Focus Areas

My applied lens consistently centers on:

- Dementia and cognitive decline  
- Aging populations  
- Menopause-stage care  

These domains represent clinically complex environments characterized by:

- Gradual symptom progression  
- Heavy reliance on patient-reported data  
- Documentation variability  
- Historical underrecognition  

They are also precisely the types of contexts where poorly governed AI systems can silently amplify inequity.

---

## Repository Architecture

### 01_medical_terminology_and_ai  
Examines how medical terminology shapes dataset construction, algorithm training, and downstream bias.  
Explores how underdocumented or ambiguously defined conditions compromise AI reliability.

---

### 02_healthcare_data_quality  
Analyzes structural weaknesses in EHR data, including incomplete documentation, inconsistent coding practices, and integration challenges between structured and unstructured records.

Focus: how upstream data issues propagate into predictive systems.

---

### 03_clinical_decision_support  
Explores the evolution from rule-based CDSS to AI-enabled advisory systems.  
Includes forward-looking scenario modeling of contextual, explainable, and workflow-integrated CDSS.

Emphasis on governance, clinician interaction models, and regulatory alignment.

---

### 04_bias_ethics_trust  
Addresses distribution shift, subgroup performance disparities, recalibration strategies, and lifecycle oversight frameworks.

Engages directly with a central governance question:

> Who determines when bias is tolerable in clinical AI—and by what criteria?

---

### 05_datasets_and_analysis  
Applies modern risk modeling principles, including:

- Calibration vs. discrimination  
- External and temporal validation  
- Post-deployment monitoring  
- Operational tradeoffs  

Examines how real-world deployment reshapes model behavior over time.

---

### 06_reflections_and_writing_samples  
Synthesizes cross-module insights into cohesive strategy-oriented analyses demonstrating:

- Systems thinking  
- Translational clinical communication  
- Regulatory awareness  
- Ethical risk framing  

---

## Governance Perspective

Healthcare AI requires more than model development capability. It demands:

- Validation across diverse populations  
- Continuous recalibration  
- Transparent model performance reporting  
- Clearly defined institutional accountability  

As AI-enabled CDSS and risk models become embedded in care pathways, governance maturity will increasingly determine clinical safety and adoption success.

---

## Positioning

This portfolio reflects a transition from technical coursework into strategic application.

It represents a growing focus on:

- AI oversight frameworks  
- Clinically grounded model evaluation  
- Responsible scaling of AI-powered decision support  
- Trust-centered AI implementation  

Healthcare AI will not be judged solely on innovation—but on its ability to earn and sustain clinical trust.

---

## Transparency Statement

ChatGPT (OpenAI) was used as a research assistance tool to support idea organization and language refinement. All cited literature and conceptual framing were independently reviewed and validated.
